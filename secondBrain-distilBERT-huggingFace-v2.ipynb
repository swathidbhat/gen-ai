{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (4.30.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (3.7.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\swathi\\appdata\\roaming\\python\\python37\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d6f502da194c5087a6ed17ce39c3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swathi\\AppData\\Roaming\\Python\\Python37\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Swathi\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cec29b8b0a4daabce7d10d9ae8c6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8d7e3ef6af47308945329d495a6676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0fc0d87307f464f80bc1ce2f2ae4ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe339b82efb746818c2e0c62cfef5d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('S:\\code\\GenAI\\deepwork.txt', 'r', encoding='utf-8') as file:\n",
    "    book_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_answer_from_book(book, question, chunk_size=512):\n",
    "    # Tokenize the book and split it into chunks\n",
    "    chunks = [book[i:i + chunk_size] for i in range(0, len(book), chunk_size)]\n",
    "    \n",
    "    best_answer = None\n",
    "    best_chunk = None\n",
    "    best_score = float('-inf')\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        answer = qa_pipeline({\"context\": chunk, \"question\": question})\n",
    "        if answer['score'] > best_score:\n",
    "            best_score = answer['score']\n",
    "            best_answer = answer['answer']\n",
    "            best_chunk = chunk\n",
    "            \n",
    "    return best_answer, best_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best answer: Dreyfus\n",
      "\n",
      "Chunk where answer was found:\n",
      " You don’t need a rarified job; you need instead a rarified approach\n",
      "to your work.\n",
      "\f",
      "    The second key observation about this line of argument is that cultivating\n",
      "craftsmanship is necessarily a deep task and therefore requires a commitment to deep\n",
      "work. (Recall that I argued in Chapter 1 that deep work is necessary to hone skills and\n",
      "to then apply them at an elite level—the core activities in craft.) Deep work, therefore,\n",
      "is key to extracting meaning from your profession in the manner described by Dreyfus\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "question = \"Who wrote Deep Work?\"\n",
    "best_answer, best_chunk = get_best_answer_from_book(book_content, question)\n",
    "print(f\"Best answer: {best_answer}\\n\\nChunk where answer was found:\\n{best_chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best answer: sychology\n",
      "\n",
      "Chunk where answer was found:\n",
      "sychology in favor of depth. Decades of research\n",
      "stemming from Csikszentmihalyi’s original ESM experiments validate that the act of\n",
      "going deep orders the consciousness in a way that makes life worthwhile.\n",
      "Csikszentmihalyi even goes so far as to argue that modern companies should embrace\n",
      "this reality, suggesting that “jobs should be redesigned so that they resemble as closely\n",
      "as possible flow activities.” Noting, however, that such a redesign would be difficult\n",
      "and disruptive (see, for example, my arguments \n"
     ]
    }
   ],
   "source": [
    "question = \"What is the best way to do deep work?\"\n",
    "best_answer, best_chunk = get_best_answer_from_book(book_content, question)\n",
    "print(f\"Best answer: {best_answer}\\n\\nChunk where answer was found:\\n{best_chunk}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
